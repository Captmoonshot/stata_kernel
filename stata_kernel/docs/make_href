#!/usr/bin/env python
# -*- coding: utf-8 -*-

from bs4 import BeautifulSoup as bs
import urllib
import re

help_msg_html = """\
<p>
See the online documentation at
<a href="https://kylebarron.github.io/stata_kernel/">
    kylebarron.github.io/stata_kernel
</a><br>
</p>
"""

with open('index.html', 'r') as f:
    soup = bs(f.read(), 'html.parser')

p = soup.find("body").find("p")
p.insert(3, bs(help_msg_html, 'lxml').html.body.p)

html_base = "https://kylebarron.github.io/stata_kernel/"
for a in soup.find_all('a', href=True):
    href = a.get('href')
    if not href.startswith('http'):
        href = re.subn(r'\.md(?=\b)', '', href, 1)[0]
        print(urllib.parse.urljoin(html_base, href))
        a['href'] = urllib.parse.urljoin(html_base, href)

with open('index.html', 'w') as f:
    f.write(str(soup))

with open('using_stata_kernel/magics.html', 'r') as f:
    soup = bs(f.read(), 'html.parser')

html_base = "https://kylebarron.github.io/stata_kernel/using_stata_kernel/"
for a in soup.find_all('a', href=True):
    href = a.get('href')
    if not href.startswith('http'):
        href = re.subn(r'\.md(?=\b)', '', href, 1)[0]
        print(urllib.parse.urljoin(html_base, href))
        a['href'] = urllib.parse.urljoin(html_base, href)

with open('using_stata_kernel/magics.html', 'w') as f:
    f.write(str(soup))
